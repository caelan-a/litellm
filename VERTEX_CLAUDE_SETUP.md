# Vertex AI Claude Proxy - Docker Setup

Easy Docker-based setup for using Claude models from Google Vertex AI via LiteLLM proxy + ngrok tunnel.

## Quick Start

### 1. Create `.env` File

```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your ngrok token
# Get token from: https://dashboard.ngrok.com/get-started/your-authtoken
```

Your `.env` file should look like:
```
NGROK_AUTHTOKEN=your_actual_token_here
```

### 2. Setup Google Cloud Credentials

```bash
# Login to Google Cloud (one-time setup)
gcloud auth application-default login
```

### 3. Start Everything

```bash
# Start proxy + ngrok in Docker
make start

# Get your public URL and Cursor config
make url
```

## Easy Commands

```bash
make start         # ğŸš€ Start proxy + ngrok
make stop-all      # ğŸ›‘ Stop everything  
make restart       # ğŸ”„ Restart everything
make url           # ğŸ“¡ Show ngrok URL & Cursor config
make proxy-status  # ğŸ“Š Show service status
make logs          # ğŸ“œ Show proxy logs
make logs-follow   # ğŸ“œ Follow logs in real-time
```

## Cursor IDE Configuration

After running `make start` and `make url`, you'll get:

```
API Base URL:  https://your-unique-id.ngrok-free.app/v1
API Key:       (any value works)

Available Models:
  â€¢ claude-sonnet-4.5
  â€¢ claude-4.5-sonnet
  â€¢ claude-4.5-sonnet-thinking
  â€¢ claude-opus-4.5
  â€¢ claude-4.5-opus
  â€¢ claude-4.5-opus-thinking
```

## Troubleshooting

### Ngrok Authentication Error

```bash
# Make sure .env file exists and has your token
cat .env | grep NGROK_AUTHTOKEN

# If missing, copy the example and edit:
cp .env.example .env
# Then edit .env with your actual token
```

### Google Cloud Authentication Error

```bash
# Re-authenticate
gcloud auth application-default login

# Check credentials exist
ls ~/.config/gcloud/application_default_credentials.json
```

### Check Logs

```bash
# Proxy logs
make logs

# Ngrok logs  
make logs-ngrok

# Follow logs in real-time
make logs-follow
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cursor    â”‚â”€â”€â”€â”€â”€â–¶â”‚    Ngrok     â”‚â”€â”€â”€â”€â”€â–¶â”‚  LiteLLM Proxy  â”‚
â”‚     IDE     â”‚      â”‚   (public)   â”‚      â”‚    (Docker)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚  Vertex AI      â”‚
                                            â”‚  Claude Models  â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## What's Running?

- **LiteLLM Proxy** (Docker container): Translates OpenAI API calls to Vertex AI format
- **Ngrok** (Docker container): Exposes proxy to the internet with HTTPS
- **Config**: Your Vertex AI project settings in `litellm_vertex_claude_config.yaml`

## Persistence

- Containers auto-restart unless stopped
- No data is stored - stateless proxy
- Ngrok URL changes on restart (unless you have a paid plan with custom domains)
